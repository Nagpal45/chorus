{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":487,"status":"ok","timestamp":1709784863959,"user":{"displayName":"ronakb","userId":"06014110381374973262"},"user_tz":-330},"id":"2kVm0sRZ8Dtq","outputId":"9f02f108-6a6e-4d86-8772-944cfde12115"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","import math\n","\n","# hand detection\n","mp_drawing = mp.solutions.drawing_utils\n","mp_hands = mp.solutions.hands\n","hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)\n","\n","# webcam\n","cap = cv2.VideoCapture(0)\n","\n","def calculate_gesture(landmarks):\n","    thumb_tip = landmarks[mp_hands.HandLandmark.THUMB_TIP.value]\n","    index_tip = landmarks[mp_hands.HandLandmark.INDEX_FINGER_TIP.value]\n","    middle_tip = landmarks[mp_hands.HandLandmark.MIDDLE_FINGER_TIP.value]\n","\n","    # pinching gesture\n","    distance = math.hypot(thumb_tip.x - index_tip.x, thumb_tip.y - index_tip.y)\n","    # global gesture_state\n","    # if gesture_state[\"pinch\"] == \"Pinched\":\n","    #     if distance > 0.08: # Adjust this threshold for release sensitivity\n","    #         if gesture_state[\"pinch\"] == \"Pause\":\n","    #             gesture_state[\"pinch\"] = \"Play\"\n","    #             print(\"Play music\")\n","    #         else:\n","    #             gesture_state[\"pinch\"] = \"Pause\"\n","    #         print({gesture_state[\"pinch\"]}, \" music\")\n","    #         return gesture_state[\"pinch\"]\n","    # elif distance < 0.05:\n","    #     gesture_state[\"pinch\"] = \"Pinched\"\n","\n","\n","    # if gesture_state[\"pinch\"] == \"Pinched\":\n","    #     prev_pinch_y = gesture_state.get(\"prev_pinch_y\", 0.5)\n","    #     distance = math.hypot(thumb_tip.x - index_tip.x, thumb_tip.y - index_tip.y)\n","    #     if distance > 0.08 and thumb_tip.y < prev_pinch_y - 0.03:\n","    #         gesture_state[\"prev_pinch_y\"] = thumb_tip.y\n","    #         print(\"Volume Up condition met\")\n","    #         return \"Volume Up\"\n","    #     gesture_state[\"prev_pinch_y\"] = thumb_tip.y\n","\n","    # if gesture_state[\"pinch\"] == \"Pinched\":\n","    #     prev_pinch_y = gesture_state.get(\"prev_pinch_y\", 0.5)\n","    #     distance = math.hypot(thumb_tip.x - index_tip.x, thumb_tip.y - index_tip.y)\n","    #     if distance > 0.08 and thumb_tip.y > prev_pinch_y + 0.03:  # Downward movement detected\n","    #         gesture_state[\"prev_pinch_y\"] = thumb_tip.y\n","    #         print(\"Volume Down condition met\")\n","    #         return \"Volume Down\"\n","    #     gesture_state[\"prev_pinch_y\"] = thumb_tip.y\n","\n","\n","    # open hand\n","    if thumb_tip.y < index_tip.y and thumb_tip.y < middle_tip.y:\n","        return \"Play\"\n","\n","    # closed hand\n","    if thumb_tip.y > index_tip.y and thumb_tip.y > middle_tip.y:\n","        return \"Pause\"\n","\n","    # L (volume control)\n","    if thumb_tip.x < index_tip.x:   return \"Volume Up\"\n","    if thumb_tip.x > index_tip.x:  return \"Volume Down\"\n","\n","    # gun shape (not working perfectly)\n","    if index_tip.y < middle_tip.y:\n","        if index_tip.x < middle_tip.x:\n","            return \"Previous\"\n","        if index_tip.x > middle_tip.x:\n","            return \"Next\"\n","\n","    return \"No Gesture Detected\"\n","\n","while cap.isOpened():\n","    success, frame = cap.read()\n","    if not success:\n","        print(\"Error reading frame from webcam.\")\n","        continue\n","\n","    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    results = hands.process(image)\n","\n","    if results.multi_hand_landmarks:\n","        for hand_landmarks in results.multi_hand_landmarks:\n","            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n","\n","            gesture = calculate_gesture(hand_landmarks.landmark)\n","            cv2.putText(image, gesture, (50, 50), cv2.FONT_HERSHEY_SIMPLEX,\n","                        1, (0, 255, 0), 2)\n","\n","    cv2.imshow('Gesture Recognition', image)\n","    if cv2.waitKey(1) == ord('q'):\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tx-R-3foAERi"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPK4EtpEVE0pdThp/cKIrnL","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
